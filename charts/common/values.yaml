global:
  # -- Set an override for the prefix of the fullname
  nameOverride:
  # -- Set the entire name definition
  fullnameOverride:
  # -- Set additional global labels. Helm templates can be used.
  labels: {}
  # -- Set additional global annotations. Helm templates can be used.
  annotations: {}

controller:
  # -- enable the controller.
  enabled: true
  # -- Set the controller type.
  # Valid options are deployment, daemonset, statefulset, cronjob, scaledjob
  type: deployment
  # -- Set annotations on the deployment/statefulset/daemonset
  annotations: {}
  # -- Set labels on the deployment/statefulset/daemonset
  labels: {}
  # -- Number of desired pods
  replicas:
  # -- Set the controller upgrade strategy
  # For Deployments, valid values are Recreate (default) and RollingUpdate.
  # For StatefulSets, valid values are OnDelete and RollingUpdate (default).
  # For Daemosets, valid values are RollingUpdate and partition is ignored.
  strategy:
  rollingUpdate:
    # -- Set deployment or daemonset RollingUpdate max unavailable
    unavailable:
    # -- Set deployment or daemonset RollingUpdate max surge
    surge:
    # -- Set statefulset RollingUpdate partition
    partition:
  # -- ReplicaSet revision history limit
  revisionHistoryLimit: 3
  # -- Set statefulset podManagementPolicy, valid values are Parallel and OrderedReady (default).
  podManagementPolicy:

image:
  # -- image repository
  repository:
  # -- image tag
  tag:
  # -- image pull policy
  pullPolicy:

# -- Set image pull secrets
imagePullSecrets: []

# -- Override the command(s) for the default container
command: []
# -- Override the args for the default container
args: []

# -- Set annotations on the pod
podAnnotations: {}

# -- Set labels on the pod
podLabels: {}

# -- Add a Horizontal Pod Autoscaler
# @default -- <disabled>
autoscaling:
  enabled: false
  target: # deploymentname
  minReplicas: # 1
  maxReplicas: # 100
  targetCPUUtilizationPercentage: # 80
  targetMemoryUtilizationPercentage: # 80

serviceAccount:
  # -- Specifies whether a service account should be created
  create: false

  # -- Annotations to add to the service account
  annotations: {}

  # -- The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

  # -- role which should be added to this account
  role: ""

  # -- Role rules which should be attached to the service account
  roleRules: []

# -- Specifies whether a service account token should be automatically mounted.
automountServiceAccountToken: true

# -- Use this to populate a secret with the values you specify.
# Be aware that these values are not encrypted by default, and could therefore visible
# to anybody with access to the values.yaml file.
secret:
  {}
  # PASSWORD: my-password

# -- Configure configMaps for the chart here.
# Additional configMaps can be added by adding a dictionary key similar to the 'config' object.
# @default -- See below
configmap:
  config:
    # -- Enables or disables the configMap
    enabled: false
    # -- Enables or disables auto-add this configmap to env
    envfrom: false
    # -- Labels to add to the configMap
    labels: {}
    # -- Annotations to add to the configMap
    annotations: {}
    # -- configMap data content. Helm template enabled.
    data:
      {}
      # foo: bar

# -- Main environment variables. Template enabled.
# Syntax options:
# A) TZ: UTC
# B) PASSWD: '{{ .Release.Name }}'
# C) PASSWD:
#      configMapKeyRef:
#        name: config-map-name
#        key: key-name
# D) PASSWD:
#      valueFrom:
#        secretKeyRef:
#          name: secret-name
#          key: key-name
#      ...
# E) - name: TZ
#      value: UTC
# F) - name: TZ
#      value: '{{ .Release.Name }}'
env:

# -- Secrets and/or ConfigMaps that will be loaded as environment variables.
# [[ref]](https://unofficial-kubernetes.readthedocs.io/en/latest/tasks/configure-pod-container/configmap/#use-case-consume-configmap-in-environment-variables)
envFrom: []
# - configMapRef:
#     name: config-map-name
# - secretRef:
#     name: secret-name

# -- Custom priority class for different treatment by the scheduler
priorityClassName: # system-node-critical

# -- Allow specifying a runtimeClassName other than the default one (ie: nvidia)
runtimeClassName: # nvidia

# -- Allows specifying a custom scheduler name
schedulerName: # awkward-dangerous-scheduler

# -- Allows specifying explicit hostname setting
hostname:

# -- When using hostNetwork make sure you set dnsPolicy to `ClusterFirstWithHostNet`
hostNetwork: false

# -- Defaults to "ClusterFirst" if hostNetwork is false and "ClusterFirstWithHostNet" if hostNetwork is true.
dnsPolicy: # ClusterFirst

# -- Optional DNS settings, configuring the ndots option may resolve nslookup issues on some Kubernetes setups.
dnsConfig: {}
#   options:
#     - name: ndots
#       value: "1"

# -- Enable/disable the generation of environment variables for services.
# [[ref]](https://kubernetes.io/docs/concepts/services-networking/connect-applications-service/#accessing-the-service)
enableServiceLinks: true

# -- Configure the Security Context for the Pod
podSecurityContext: {}

# -- Configure the Security Context for the main container
securityContext: {}

# -- Configure the lifecycle for the main container
lifecycle: {}

# -- Specify any initContainers here as dictionary items. Each initContainer should have its own key.
# The dictionary item key will determine the order. Helm templates can be used.
initContainers: {}

# -- Specify any additional containers here as dictionary items. Each additional container should have its own key.
# Helm templates can be used.
additionalContainers: {}

# -- Probe configuration
# -- [[ref]](https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/)
# @default -- See below
probes:
  # -- Liveness probe configuration
  # @default -- See below
  liveness:
    # -- Enable the liveness probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own livenessProbe
    custom: false
    # -- The spec field contains the values for the default livenessProbe.
    # If you selected `custom: true`, this field holds the definition of the livenessProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 1
      failureThreshold: 3

  # -- Redainess probe configuration
  # @default -- See below
  readiness:
    # -- Enable the readiness probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own readinessProbe
    custom: false
    # -- The spec field contains the values for the default readinessProbe.
    # If you selected `custom: true`, this field holds the definition of the readinessProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 0
      periodSeconds: 10
      timeoutSeconds: 1
      failureThreshold: 3

  # -- Startup probe configuration
  # @default -- See below
  startup:
    # -- Enable the startup probe
    enabled: true
    # -- Set this to `true` if you wish to specify your own startupProbe
    custom: false
    # -- The spec field contains the values for the default startupProbe.
    # If you selected `custom: true`, this field holds the definition of the startupProbe.
    # @default -- See below
    spec:
      initialDelaySeconds: 0
      timeoutSeconds: 1
      ## This means it has a maximum of 5*30=150 seconds to start up before it fails
      periodSeconds: 5
      failureThreshold: 30

termination:
  # -- Configure the path at which the file to which the main container's termination message will be written.
  # -- [[ref](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#lifecycle-1)]
  messagePath:

  # -- Indicate how the main container's termination message should be populated.
  # Valid options are `File` and `FallbackToLogsOnError`.
  # -- [[ref](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#lifecycle-1)]
  messagePolicy:

  # -- Duration in seconds the pod needs to terminate gracefully
  # -- [[ref](https://kubernetes.io/docs/reference/kubernetes-api/workload-resources/pod-v1/#lifecycle)]
  gracePeriodSeconds:

# -- Configure the services for the chart here.
# Additional services can be added by adding a dictionary key similar to the 'main' service.
# @default -- See below
service:
  main:
    # -- Enables or disables the service
    enabled: false

    # -- Make this the primary service (used in probes, notes, etc...).
    # If there is more than 1 service, make sure that only 1 service is marked as primary.
    primary: true

    # -- Export the service to other clusters in fleet.
    export: false

    # -- Override the name suffix that is used for this service
    nameOverride:

    # -- Set the service type
    type: ClusterIP

    # -- Specify the externalTrafficPolicy for the service. Options: Cluster, Local
    # -- [[ref](https://kubernetes.io/docs/tutorials/services/source-ip/)]
    externalTrafficPolicy:

    # -- Specify the ip policy. Options: SingleStack, PreferDualStack, RequireDualStack
    ipFamilyPolicy:
    # -- The ip families that should be used. Options: IPv4, IPv6
    ipFamilies: []

    # -- Provide additional annotations which may be required.
    annotations: {}

    # -- Provide additional labels which may be required.
    labels: {}

    # -- Configure the Service port information here.
    # Additional ports can be added by adding a dictionary key similar to the 'http' service.
    # @default -- See below
    ports:
      http:
        # -- Enables or disables the port
        enabled: false

        # -- Make this the primary port (used in probes, notes, etc...)
        # If there is more than 1 service, make sure that only 1 port is marked as primary.
        primary: true

        # -- The port number
        port:

        # -- Port protocol.
        # Support values are `HTTP`, `HTTPS`, `TCP` and `UDP`.
        # HTTPS and HTTPS spawn a TCP service and get used for internal URL and name generation
        protocol: HTTP

        # -- Specify a service targetPort if you wish to differ the service port from the application port.
        # If `targetPort` is specified, this port number is used in the container definition instead of
        # the `port` value. Therefore named ports are not supported for this field.
        targetPort:

        # -- Specify the nodePort value for the LoadBalancer and NodePort service types.
        # [[ref]](https://kubernetes.io/docs/concepts/services-networking/service/#type-nodeport)
        nodePort:

# -- Configure the ingresses for the chart here.
# Additional ingresses can be added by adding a dictionary key similar to the 'main' ingress.
# @default -- See below
ingress:
  main:
    # -- Enables or disables the ingress
    enabled: false

    # -- Make this the primary ingress (used in probes, notes, etc...).
    # If there is more than 1 ingress, make sure that only 1 ingress is marked as primary.
    primary: true

    # -- Override the name suffix that is used for this ingress.
    nameOverride:

    # -- Provide additional annotations which may be required.
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"

    # -- Provide additional labels which may be required.
    labels: {}

    # -- Set the ingressClass that is used for this ingress.
    # Requires Kubernetes >=1.19
    ingressClassName: # "nginx"

    # Create GKE managed-certs for ingress hosts
    provisionGoogleManagedCert: false

    ## Configure the hosts for the ingress
    hosts:
      # -- Host address. Helm template can be passed.
      - host: chart-example.local
        ## Configure the paths for the host
        paths:
          # -- Path.  Helm template can be passed.
          - path: /
            # -- Ignored if not kubeVersion >= 1.14-0
            pathType: Prefix
            service:
              # -- Overrides the service name reference for this path
              name:
              # -- Overrides the service port reference for this path
              port:

    # -- Configure TLS for the ingress. Both secretName and hosts can process a Helm template.
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

# -- Configure persistence for the chart here.
# Additional items can be added by adding a dictionary key similar to the 'config' key.
# [[ref]](http://docs.k8s-at-home.com/our-helm-charts/common-library-storage)
# @default -- See below
persistence:
  # -- Default persistence for configuration files.
  # @default -- See below
  config:
    # -- Enables or disables the persistence item
    enabled: false

    # -- Sets the persistence type
    # Valid options are pvc, emptyDir, hostPath, secret, configMap or custom
    type: pvc

    # -- Where to mount the volume in the main container.
    # Defaults to `/<name_of_the_volume>`,
    # setting to '-' creates the volume but disables the volumeMount.
    mountPath: # /config
    # -- Specify if the volume should be mounted read-only.
    readOnly: false
    # -- Override the name suffix that is used for this volume.
    nameOverride:

    # -- Storage Class for the config volume.
    # If set to `-`, dynamic provisioning is disabled.
    # If set to something else, the given storageClass is used.
    # If undefined (the default) or set to null, no storageClassName spec is set, choosing the default provisioner.
    storageClass: # "-"

    # -- If you want to reuse an existing claim, the name of the existing PVC can be passed here.
    existingClaim: # your-claim

    # -- Used in conjunction with `existingClaim`. Specifies a sub-path inside the referenced volume instead of its root
    subPath: # some-subpath

    # -- AccessMode for the persistent volume.
    # Make sure to select an access mode that is supported by your storage provider!
    # [[ref]](https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes)
    accessMode: ReadWriteOnce

    # -- The amount of storage that is requested for the persistent volume.
    size: 1Gi

    # -- Set to true to retain the PVC upon `helm uninstall`
    retain: false

    # -- Set to true to create PV with existent cloud disk
    existingDisk: false
    # -- Fill with required csi provider values
    csi:
      driver: ""
      volumeHandle: ""
      fsType: ext4

    # -- Labels to select corresponding PV.
    selectorLabels: {}

  # -- Create an emptyDir volume to share between all containers
  # [[ref]]https://kubernetes.io/docs/concepts/storage/volumes/#emptydir)
  # @default -- See below
  shared:
    enabled: false
    type: emptyDir
    mountPath: /shared

    # -- Set the medium to "Memory" to mount a tmpfs (RAM-backed filesystem) instead
    # of the storage medium that backs the node.
    medium: # Memory

    # -- If the `SizeMemoryBackedVolumes` feature gate is enabled, you can
    # specify a size for memory backed volumes.
    sizeLimit: # 1Gi

# -- Used in conjunction with `controller.type: statefulset` to create individual disks for each instance.
volumeClaimTemplates: []
# - name: data
#   mountPath: /data
#   accessMode: "ReadWriteOnce"
#   datasource:
#     apiGroup: snapshot.storage.k8s.io/v1
#     kind: VolumeSnapshot
#     name: my-snapshot
#   size: 1Gi
# - name: backup
#   mountPath: /backup
#   subPath: theSubPath
#   accessMode: "ReadWriteOnce"
#   size: 2Gi
#   storageClass: cheap-storage-class

# -- Node selection constraint
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#nodeselector)
nodeSelector: {}

# -- Defines affinity constraint rules.
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#affinity-and-anti-affinity)
affinity: {}

# -- Defines topologySpreadConstraint rules.
# [[ref]](https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/)
topologySpreadConstraints: []
# - maxSkew: <integer>
#   topologyKey: <string>
#   whenUnsatisfiable: <string>
#   labelSelector: <object>

# -- Specify taint tolerations
# [[ref]](https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/)
tolerations: []

# -- Use hostAliases to add custom entries to /etc/hosts - mapping IP addresses to hostnames.
# [[ref]](https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/)
hostAliases: []
# - ip: "192.168.1.100"
#   hostnames:
#   - "example.com"
#   - "www.example.com"

# -- Set the resource requests / limits for the main container.
resources:
  {}
  ## We usually recommend not to specify default resources and to leave this as a conscious
  ## choice for the user. This also increases chances charts run on environments with little
  ## resources, such as Minikube. If you do want to specify resources, uncomment the following
  ## lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

serviceMonitor:
  ## @param metrics.serviceMonitor.enabled Create ServiceMonitor object
  ##
  enabled: false
  ## @param metrics.serviceMonitor.port port on which prometheus metrics are exposed
  ##
  port: "metrics"
  ## @param metrics.serviceMonitor.path path on which prometheus metrics are exposed
  ##
  path: "/metrics"
  ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running
  ##
  namespace: ""
  ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped
  ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  ##
  interval: ""
  ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
  ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint
  ##
  scrapeTimeout: ""
  ## @param metrics.serviceMonitor.selector Additional labels for ServiceMonitor object
  ## ref: https://github.com/bitnami/charts/tree/master/bitnami/prometheus-operator#prometheus-configuration
  ## e.g:
  ## selector:
  ##   prometheus: my-prometheus
  ##
  selector: {}
  ## @param metrics.serviceMonitor.metricRelabelings Specify Metric Relabelings to add to the scrape endpoint
  ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#relabelconfig
  ##
  metricRelabelings: []
  ## @param metrics.serviceMonitor.relabelings [array] Prometheus relabeling rules
  ##
  relabelings: []
  ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint
  ##
  honorLabels: false
  ## DEPRECATED metrics.serviceMonitor.additionalLabels will be removed in a future release - Please use metrics.serviceMonitor.labels instead
  ## @param metrics.serviceMonitor.labels Used to pass Labels that are required by the installed Prometheus Operator
  ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#prometheusspec
  ##
  labels: {}
  ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.
  ##
  jobLabel: ""

## cronjob spec https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/
## pod details should overwriteen under controller spec values.
cronJob:
  ## @param schedule policy for cronjob in cron format
  schedule: ""
  ## @param successfulJobsHistoryLimit policy for cronjob
  successfulJobsHistoryLimit: 3
  ## @param failedJobsHistoryLimit policy for cronjob
  failedJobsHistoryLimit: 3
  ## @param startingDeadlineSeconds policy for cronjob
  startingDeadlineSeconds: 120
  ## @param restart policy for cronjob
  restartPolicy: ""
  suspend: false

# spec for GKE l4 lb
l4gkelb:
  # -- Enables or disables creation of the GKE l4 external lb
  enabled: false
  # @param hostname of lb. Note - this requires working external-dns with service type enabled
  host: random.hostname.com
  # @param type of lb - internal or external
  type: internal
  # @param allow global access (used in internal lb)
  allowGlobalAccess: false
  # @param exposed port of this LB
  port: 8080
  # @param protocol used by this LB tcp\udp
  protocol: TCP
  # @param name of targetport of pod to send traffic to
  targetPort: TCPPORT

## spec for GKE BackendConfig
## ref: https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-features#create_backendconfig
backendconfig:
  # -- Enables or disables creation of the backendconfig, for now will be used for all service ports
  enabled: false
  # @param type of backendconfig - can be ingress or gateway
  # ingress: Generates backenconfig sutible for GCE-ingress
  # more - https://cloud.google.com/kubernetes-engine/docs/how-to/ingress-configuration#configuring_ingress_features_through_backendconfig_parameters
  # gateway: Generates GCPBackendPolicy and HealthCheckPolicy suitible for GCE-gateway
  # more - https://cloud.google.com/kubernetes-engine/docs/concepts/gateway-api#policy
  type: ingress
  ## Timeout for backendconfig
  timeoutSec: 30
  # @param - disable logs for gateways for this service
  gatewayLogs: true
  # @param - log sampling param, value 0% and 100%. Works only on gateway type
  logSamplingPercentage: 100
  ## block defines settings of healthCheck for backendconfig
  healthCheck:
    ## @param timeoutSec for backendconfig's healthCheck
    timeoutSec: 1
    ## @param checkIntervalSec for backendconfig's healthCheck
    checkIntervalSec: 5
    ## @param healthyThreshold for backendconfig's healthCheck
    healthyThreshold: 1
    ## @param unhealthyThreshold for backendconfig's healthCheck
    unhealthyThreshold: 3
    ## @param port for backendconfig's healthCheck
    port: 80
    ## @param type for backendconfig's healthCheck
    type: HTTP
    ## @param requestPath for backendconfig's healthCheck
    requestPath: /health
    # @param - disable logs for gateway-based health check
    logConfig: true
  # Additionaly attach GKE security policy to backendconfig
  # ref: https://cloud.google.com/armor/docs/security-policy-overview
  #securityPolicy:
  #  name: "some-policy-name"

# Set the VM alert rules for chart
alertRules:
  []
  # Each element defines one alert
  #memory:
  # You can both use plain promql, and helm-templated values
  #promql: "{{ .Release.Namespace }}"
  # Compare element between @promql and threshold
  #compare: ">"
  # Thresholds for creating Warning\Critical\info\log alert. Should be NULL if warning\critical\info\log not needed. Supports P1\P2\P3\P4. Can be value\promql\helm-template
  #thresholds:
  #  P1: 10
  #  warning: 9
  #  P3: some
  #  log: another
  # Duration of alert to checked as firing
  #duration: 5m
  # Annotations for alerts. description, summary and runbook should be set to alert be created.
  #annotations:
  #description: some-new-alert
  #summary: something goes wrong
  #runbook_url: http://example.com
  # Additional labels for alert
  #labels:
  #  some_label: 1
  #  another_label: 2
  # Webhooks for webhook-uptime integration
  #webhooks:
  #  warning: "http://some.url"
  #  critical: "http://another.url"

# Set the Prometheus alert rules  for chart
alerts:
  []
  # Each element defines one alert
  #memory:
  # You can both use plain promql, and helm-templated values
  #promql: "{{ .Release.Namespace }}"
  # Compare element between @promql and threshold
  #compare: ">"
  # Thresholds for creating Warning\Critical\info\log alert. Should be NULL if warning\critical\info\log not needed. Supports P1\P2\P3\P4. Can be value\promql\helm-template
  #thresholds:
  #  P1: 10
  #  warning: 9
  #  P3: some
  #  log: another
  # Duration of alert to checked as firing
  #duration: 5m
  # Annotations for alerts. description, summary and runbook should be set to alert be created.
  #annotations:
  #description: some-new-alert
  #summary: something goes wrong
  #runbook_url: http://example.com
  # Additional labels for alert
  #labels:
  #  some_label: 1
  #  another_label: 2

## scaledjob spec https://keda.sh/docs/2.8/concepts/scaling-jobs/
## pod details should have overwritten under controller spec values.
scaledjob:
  ## @param jobTargetRef Kubernetes job template and other misc settings
  jobTargetRef:
    ## @param max number of desired pods
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#controlling-parallelism
    parallelism: 1
    ## @param desired number of successfully finished pods
    ## ref: https://kubernetes.io/docs/concepts/workloads/controllers/jobs-run-to-completion/#controlling-parallelism
    completions: 1
    ## @param Specifies the duration in seconds relative to the startTime that the job may be active before the system tries to terminate it; value must be positive integer
    activeDeadlineSeconds: 600
    ## @param Specifies the number of retries before marking this job failed. Defaults to 6
    backoffLimit: 6
    ## @param restart policy for cronjob
    restartPolicy: "Never"
  ## @param Optional. Default: 30 seconds
  pollingInterval: 30
  ##  @param Optional. Default: 100. How many completed jobs should be kept.
  successfulJobsHistoryLimit: 5
  ## @param Optional. Default: 100. How many failed jobs should be kept.
  failedJobsHistoryLimit: 5
  ## @param # Optional. Default: 0
  minReplicaCount: 10
  ## @param  # Optional. Default: 100
  maxReplicaCount: 100
  ## block defines settings of rollout for scaledjob
  rollout:
    ## @param Optional. Default: default. Which Rollout Strategy KEDA will use.
    strategy: default
    ## @param # Optional. Default: background. Kubernetes propagation policy for cleaning up existing jobs during rollout.
    propagationPolicy: background
  ## block defines settings of rollout for scaledjob
  scalingStrategy:
    ## @param Optional. Default: default. Which Scaling Strategy to use.
    strategy: "default"
    ## @param Optional. A parameter to optimize custom ScalingStrategy.
    customScalingQueueLengthDeduction: 1
    ## @param Optional. A parameter to optimize custom ScalingStrategy.
    customScalingRunningJobPercentage: "0.5"
    ## @param  Optional. A parameter to calculate pending job count per the specified pod conditions
    pendingPodConditions:
      - "Ready"
      - "PodScheduled"
      - "AnyOtherCustomPodCondition"
    ## @param Optional. Default: max. Specifies how to calculate the target metrics when multiple scalers are defined.
    multipleScalersCalculation: "max"
  ## block defines settings of Keda for triggers
  ## ref https://keda.sh/docs/2.8/scalers/
  ## valid type are prometheus.
  triggers:
    []
    # - type: prometheus
    #   metadata:
    #     # Required fields:
    #     serverAddress: http://prom-host:9093
    #     metricName: http_requests_total
    #     query: sum(rate(http_requests_total{deployment="my-deployment"}[2m]))
    #     threshold: '100.50'
    #     activationThreshold: '5.5'
    #     # Optional fields:
    #     namespace: example-namespace
    #     ignoreNullValues: false

## scaledObject spec https://keda.sh/docs/2.14/concepts/scaling-deployments/
## pod details should have overwritten under controller spec values.
scaledObject:
  # @param metrics.scaledObject.enabled Creates Keda ScaledObject
  enabled: false
  ## @param # Optional. Default: 1
  # minReplicaCount: 1
  ## @param  # Optional. Default: 2
  # maxReplicaCount: 2
  ## @param Optional. Default: 30 seconds
  # pollingInterval: 30
  ## @param Optional. Default: 300 seconds
  # cooldownPeriod: 300
  ## @param Optional. Default: 300 seconds
  # stabilizationWindowSeconds: 300
  ## @param Optional. Default: false
  # paused: false
  ## @param # Optional. Default: 0
  # pausedReplicas: 0
  ## block defines settings of Keda for triggers
  ## ref https://keda.sh/docs/2.14/scalers/
  ## valid type are prometheus, postgresql, cpu and memory.
  # triggers:
    # - type: prometheus
    #   metricType: AverageValue
    #   metadata:
    #     # Required fields:
    #     serverAddress: http://prom-host:9093
    #     metricName: http_requests_total
    #     query: sum(rate(http_requests_total{deployment="my-deployment"}[2m]))
    #     queryParameters: key-1=value-1,key-2=value-2
    #     threshold: '100.50'
    #     activationThreshold: '5.5'
    #     # Optional fields:
    #     namespace: example-namespace
    #     ignoreNullValues: false

pdb:
  enabled: false
  maxUnavailable: 1

## Grafana dashboards
dashboards: {}
  # general:
  #  base64 encoded Grafana dashboard json file
  #  base64: "ewogICJhbm5vdGF0aW9ucyI6IHsKICAgICJsaXN0IjogWwogICAgICB7CiAgICAgICAgImJ1aWx0S"
  # protocol:
  #  json: |-
  #    {
  #      "annotations": {
  #        "list": [
  #          {
  #            "builtIn": 1,
  #            "datasource": {
  #              "type": "grafana",
  #              "uid": "-- Grafana --"
  #            },
  #            "enable": true,
  #            "hide": true,
  #            "iconColor": "rgba(0, 211, 255, 1)",
  #            "name": "Annotations & Alerts",
  #            "type": "dashboard"
  #          }
  #        ]
  #      },
  #      "description": "Dashboard for monitoring a Celestia node and key hardware performance metrics",
  #      "editable": true,
  #      "fiscalYearStartMonth": 0,
  #      "graphTooltip": 0,
  #      "id": 26,
  #      "links": [],
  #      "panels": []
  #    }

## Additional resources to provision.
extraDeploy: {}